{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Abstractive Processing for Tree Organized Retrieval \n",
    "RAPTOR introduces a novel approach to retrieval-augmented language models by constructing a recursive tree structure from documents. RAPTOR takes an innovative method to retrieval-augmented language models by creating a recursive tree structure from texts. This enables more efficient and context-aware information retrieval from huge texts, solving major constraints in traditional language models.\n",
    "\n",
    "The RAPTOR study proposes an innovative approach for indexing and retrieval of documents.\n",
    "* The leaves are a collection of starter documents.\n",
    "* Leaves are embedded and crowded.\n",
    "* Clusters are then combined into higher-level (more abstract) consolidations of information from related documents.\n",
    "* This is done recursively, resulting in a \"tree\" of raw documents (leaves) that lead to more abstract summaries.\n",
    "\n",
    "\n",
    "This tree structure is critical to the RAPTOR function because it captures both high-level and detailed aspects of text, which is especially beneficial for complex theme questions and multi-step reasoning in questioning and answering activities.\n",
    "\n",
    "Documents are segmented into shorter texts known as chunks, which are then embedded using an embedding model. A clustering method is then used to group these embeddings together. After clusters are formed, the text linked with each cluster is summarized using an LLM.\n",
    "\n",
    "The summaries are created as nodes in a tree, with higher-level nodes delivering more abstract summaries.\n",
    "\n",
    "\n",
    "Here's the paper link:[RAPTOR](https://arxiv.org/html/2401.18059v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "euXB2biyFgCm"
   },
   "outputs": [],
   "source": [
    "# !pip install langchain torch sentence_transformers pypdf umap-learn langchain-community langchain-cohere tiktoken langchain-huggingface langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KLXV44HbF4hE"
   },
   "outputs": [],
   "source": [
    "# %pip install --upgrade --quiet  langchain_milvus\n",
    "# !pip uninstall -y grpcio pymilvus\n",
    "# !pip install grpcio==1.60.1 pymilvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-fMFRqjIGVnH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import umap\n",
    "import base64\n",
    "import tiktoken\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from typing import Dict, List, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9KryBFfzG9qm"
   },
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the LLM Model:\n",
    "* Here we use the Groq API to access the open-source LLaMA3 model.\n",
    "* The Groq API, combined with the powerful capabilities of Llama 3, offers an innovative approach to building and deploying machine learning models.\n",
    "* Groq, known for its high-performance AI accelerators, provides an efficient and scalable platform for running complex AI workloads.\n",
    "* Llama 3, a state-of-the-art language model, leverages these capabilities to deliver robust natural language processing (NLP) solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gW9iruXzHNYO"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GROQ_API_KEY'] = 'YOUR_GROQ_API_KEY'\n",
    "\n",
    "model = ChatGroq(model_name=\"Llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "Here, we used legal books as input data for our analysis. Each PDF file is over 300 pages. The PDF links for these books are provided below.:\n",
    "* [Family Law](https://lawfaculty.du.ac.in/userfiles/downloads/LLBCM/Ist%20Term_Family%20Law-%20I_LB105_2023.pdf)\n",
    "* [Administrative Law](https://lawfaculty.du.ac.in/userfiles/downloads/LLBCM/IVth%20Term_Administrative%20Law_LB%20402_2023.pdf)\n",
    "* [Labour Law](https://www.icsi.edu/media/webmodules/Labour_Laws&_Practice.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S-O8bKvgHU_o",
    "outputId": "adf50a76-64a4-4d8a-9a75-130819eee4c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 12 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 14 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 16 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 18 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 20 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 22 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 24 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 26 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 28 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 35 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 37 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 39 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 41 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 43 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 45 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 47 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 52 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 54 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 56 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 61 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 63 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 65 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 70 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 72 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 74 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 79 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 84 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 86 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 88 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 93 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 102 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 104 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 106 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 111 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 116 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 152 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 223 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 231 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 240 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 276 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 278 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 286 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 288 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 312 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 564 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 635 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 649 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 695 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 757 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 764 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 831 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 893 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 1020 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "# # load PDF files from a directory\n",
    "loader = PyPDFDirectoryLoader(\"/content/drive/MyDrive/rag_with_raptor/books\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uSCMfkmoN0Zn"
   },
   "outputs": [],
   "source": [
    "# Extract text content from the documents\n",
    "texts = [doc.page_content for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1rDrhuDAH6OQ",
    "outputId": "a4b33065-ba89-4aa7-bdc4-6b4dc4a38e9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['     \\n    LL.B. I Term    LB – 105: Family Law – I   Cases Selected and Edited by Usha Tandon Kiran Gupta Vandana Manju Relan P.B. Pankaja Pinki Sharma Neha Aneja     FACULTY OF LAW UNIVERSITY OF DELHI, DELHI-110007 January, 2023  (For private use only in the course of instruction) \\n',\n",
       " '   Semester- First Course Name- Family Law-I Course Code- LB-105 Core course: 5 credits; Classes – 64 (4 Classes/week + Tutorial) Course Objectives: 1. To create awareness and educate the students about rights and duties of members of family towards each other, with special reference to spousal relationship. 2. To give overview to the students and enhance their understanding on the current laws on marriage, divorce, maintenance, adoption and guardianship. 3. To give practical exposure to students by field visit of Family Courts, Mediation and Conciliation Centres etc.  Course Learning Outcomes:  1. Students will be able to practice in Law Courts as a specialized Matrimonial Lawyer. 2. Students will be able to join Research Houses, especially on issues relating to women and children at domestic and international level.  Unit I: Marriage under Hindu Law  Concept of marriage in general: Nature of Hindu Marriage; Applicability of Legislation (Section 2 of HMA, 1955); Conditions for the validity of marriage (sections 3 and 5 of HMA, 1955); Solemnisation of marriage with special reference to live in relationship (section 7 of HMA, 1955 r/w Section 114 Indian Evidence Act); Registration of Marriage (section 8 of HMA, 1955); Void marriages (sections 11 r/w 17, 18 of HMA, 1955 r/w section 494 and 495 IPC); Voidable marriage (section 12).  Case:  01 Dr. Surajmani Stella Kujur v. Durga Charan Hansdah, 1 AIR 2001 SC 938 02 S. Nagalingam v. Sivagami (2001) 7 SCC 487 4 03 Bhaurao Shankar Lokhande v. State of Maharashtra, AIR 1965 SC 1564 8 04 Lily Thomas v. Union of India, AIR 2000 SC 1650 12 05 Pinninti Venkataramana v. State, AIR 1977 AP 43 23 06 Asha Qureshi v. Afaq Qureshi, AIR 2002 MP 263 33 07 Court On Its Own Motion Lajja ... vs State, 2012 (193) DLT 61 37 08 P. v. K., AIR 1982 Bom. 400 56 09 Babui Panmato Kuer v. Ram Agya Singh, AIR 1968 Pat. 190 66 10 Seema v. Ashwani Kumar (2006) 2 SCC 578 70 ',\n",
       " '    Unit II: Matrimonial Remedies under Hindu Law  Restitution of Conjugal Rights (Section 9 of HMA, 1955); Judicial Separation [section 10 and 13 (IA) of HMA, 1955]; Divorce [ sections 13(1), (2), 13 (1A), 13 A, 13B of HMA, 1955) (a) Theories of Divorce (b) Grounds of Divorce with particular emphasis on Cruelty, Desertion, Option of Puberty, Mutual Consent, Irretrievable Breakdown of Marriage: Seventy-first Report of Law Commission of India; Marriage Laws Amendment Bill 2013.  Cases:  01. Kailashwati v. Ayudhia Parkash, 1977 C.L.J. 109 (P.& H.) 74 02. Swaraj Garg v. K.M. Garg, AIR 1978 Del. 296 85 03. Saroj Rani v. Sudarshan Kumar, AIR 1984 SC 1562 93 04. N.G. Dastane v. S. Dastane, AIR 1975 SC 1534 100 05. Sanjeev Gupta v Ritu Gupta, 2019 SCC Online All 2255, (decided on 25 May, 2019) 06. Samar Ghosh v. Jaya Ghosh, 2007 (3) SCJ 253 120 07. Bipinchandra Jaisinghbai Shah v. Prabhavati, AIR 1957 SC 176 141 08. Dharmendra Kumar v. Usha Kumar, AIR 1977 SC 2213 158 09. T. Srinivasan v. T. Varalakshmi, 1 (1991) DMC 20 (Mad.) 161 10. Hirachand Srinivas Managaonkar v. Sunanda, AIR 2001 SC 1285 168 11. Sureshta Devi v. Om Prakash, 1 (1991) DMC 313 (SC) 174 12. Amardeep Singh v. Harveen Kaur, SC, (decided on 12 Sep, 2017)  Unit III: Maintenance under Hindu Law The Hindu Marriage Act, 1955, sections 24 and 25;The Hindu Adoptions and Maintenance Act, 1956, section 18; The Criminal Procedure Code, 1973, section 125; Protection of Women from Domestic Violence Act 2005.  Cases: 01. Amar Kanta Sen v. Sovana Sen, AIR 1960 Cal. 438 178 02. D.Velusamy v. D.Patchaiammal (2010) 10 SCC 469 181 03. Badshah v. Sou. Urmila Badshah Godse & Anr(2014)1SCC188 188 04. Padmja Sharma v. Ratan Lal Sharma, AIR 2000 SC 1398 Unit IV: Adoption( Read With CARA Guidelines 2017) The Hindu Adoptions and Maintenance Act, 1956 Cases: 01. Brijendra v. State of M.P.,  AIR 2008 SC 1058 196 ',\n",
       " '02. In Re: Adoption of Payal at Sharinee Vinay Pathak and his wife Sonika Sahay Pathak, 2010 (1) Bom CR 434 201 03. Shabnam Hashmi v. Union of India (UOI) and Ors. 2014 (2) SCALE529 04 Manju Sharma v.Vipin, 2019 SCC Online Del 8960 (decided on 1 July, 2019)  Unit V: Minority and Guardianship under Hindu Law The Hindu Minority and Guardianship Act, 1956  Case: 01. Githa Hariharan v. Reserve Bank of India (1999) 2 SCC 228 211  Unit VI: Sources and Schools of Muslim Law Unit VII: Marriage under Muslim law Nikah - Solemnisation of Marriage – conditions for validity, classification and types; Dower  Cases: 01 Ms. Ghulam Kubra Bibi v. Mohd. Shafi Mohd. Din, AIR 1940 Pesh. 2 223 02 Chand Patel v. Bismillah Begum, 1 (2008) DMC 588 (SC) 225 03 Saiyid Rashid Ahmad v.  Mt. Anisa Khatun, AIR 1932 PC 25 233   Unit VIII: Divorce under Muslim law  Extra-judicial - Talaq, Khula, Mubarat (b) Judicial - The Dissolution of Muslim Marriages Act, 1939  Cases:  01 Shamim Ara v. State of U.P., 2002 Cr LJ 4726 (SC)  237 02 Masroor Ahmed v. Delhi (NCT) 2008 (103) DRJ 137 (Del.)  242 03 Ghulam Sakina v. Falak Sher Allah Baksh, AIR 1950 Lah. 45 255 04 A. Yousuf Rawther v. Sowramma, AIR 1971 Ker. 261  259 05 Itwari v. Asghari, AIR 1960 All. 684  269 06 Shayara Bano v UOI, SC, decided on 22 August, 2017      Unit IX: Maintenance under Muslim law  Cases: 01. Danial Latifi v. Union of India  (2001) 7 SCC 740 276 ',\n",
       " '    02 Noor Saba Khatoon v. Mohd. Quasim, AIR 1997 SC 3280 291  Suggested Readings:  Prescribed Legislations: 1. The Hindu Marriage Act, 1955 2. The Hindu Adoptions and Maintenance Act, 1956 3. The Hindu Minority and Guardianship Act, 1956 4. The Dissolution of Muslim Marriages Act, 1939 5. The Muslim Woman (Protection of Rights on Divorce) Act, 1986 6. Prohibition of Child Marriages Act, 2006 7. Protection of Women from Domestic Violence Act, 2005.  Prescribed Books:  1. Ranganath Misra (Rev.), Mayne’s Treatise on Hindu Law & Usage 2. Satyajeet A. Desai, Mulla’s Principles of Hindu Law 3. Paras Diwan, Law of Marriage and Divorce 4. M. Hidayatulla and Arshad Hidayatulla, Mulla’s Priciples of Mohomedan Law 5. Tahir Mahmood, Fyzee’s Outlines of Muhammedan Law  Teaching Plan:  Week 1: Marriage under Hindu Law Week 2: Marriage under Hindu Law Week 3: Marriage under Hindu Law Week 4: Marriage under Hindu Law Week 5: Restitution of Conjugal Rights and Judicial Separation under Hindu Law Week 6: Divorce under Hindu Law Week 7: Divorce under Hindu Law Week 8; Maintenance under Hindu Law Week 9: Maintenance and Adoption under Hindu Law Week 10: Adoption, Minority and Guardianship under Hindu Law Week 11: Sources and Schools of Muslim law; Marriage under Muslim law Week 12: Marriage under Muslim law (Classification of Marriage) Week 13: Divorce under Muslim law Week 14: Divorce under Muslim law ',\n",
       " '   Facilitating the achievement of Course Learning Outcomes  Unit No. Course Learning Outcomes Teaching and Learning Activity Assessment Tasks 1. Marriage under Hindu Law Case Discussion; Lecture Method and Moot Court Methodology As given below 2. Matrimonial Remedies under Hindu Law Case Discussion; Lecture Method and Moot Court Methodology As given below 3. Maintenance under Hindu Law Case Discussion; Lecture Method and Moot Court Methodology As given below 4. Adoption under Hindu Law Case Discussion; Lecture Method As given below 5. Minority and Guardianship under Hindu Law Case Discussion; Lecture Method As given below 6. Sources and  Schools  of  Muslim law Lecture Method As given below 7. Marriage under Muslim la Case Discussion; Lecture Method And Moot Court Methodology As given below 8. Divorce under Muslim Law Case Discussion; Lecture Method As given below 9. Maintenance under Muslim law Case Discussion; Lecture Method As given below    IMPORTANT NOTE:  1. The topics, cases and suggested readings given above are not exhaustive. The Committee of teachers teaching the Course shall be at liberty to revise the topics/case/suggested readings. 2. Students are required to study/refer to the legislations as amended from time to time, and consult the latest editions of books.  **** ',\n",
       " \"   Rubric for Theory Exam Papers:    'All the theory papers, except for CLE subjects*, for LL.B. semester exams carry 100 marks each, for which the University of Delhi conducts an end semester descriptive exam of 3 hours duration.  A typical theory question paper contains 8 questions printed both in English and Hindi languages. The student is required to answer 5 out of 8 questions. Each question carries equal marks, that is 20 marks each. Hence the maximum marks for each paper is 100. A student has to secure a minimum of 45 marks out of 100 to pass a paper. Answers may be written either in English or in Hindi but the same medium should be used throughout the paper.'     *****************************************************************         \",\n",
       " ' Surajmani Stella Kujur v. Durga Charan Hansdah AIR 2001 SC 938 : (2001) 3 SCC 13 R.P. SETHI, J. - 2. Who is a “Hindu” for the purposes of the applicability of the Hindu Marriage Act, 1955 (“the Act”) is a question of law to be determined in this appeal. 3. Section 2 of the Act specifies the persons to whom the Act is applicable. Clauses (a), (b) and (c) of sub-section (1) of Section 2 make the Act applicable to a person who is a Hindu by religion in any of its forms or developments including a Virashaiva, a Lingayat or a follower of the Brahmo, Prarthana or Arya Samaj and to a person who is a Buddhist, Jain or Sikh by religion. It is also applicable to any other person domiciled in the territories of India who is not a Muslim, Christian, Parsi or Jew by religion. The applicability of the Act is, therefore, comprehensive and applicable to all persons domiciled in the territory of India who are not Muslims, Christians, Parsis or Jews by religion. 4. The term “Hindu” has not been defined either under the Act or the Indian Succession Act or any other enactment of the legislature. As far back as in 1903 the Privy Council in Bhagwan Koer v. J.C. Bose [ILR (1902) 31 Cal 11, 15] observed: We shall not attempt here to lay down a general definition of what is meant by the term ‘Hindu’. To make it accurate and at the same time sufficiently comprehensive as well as distinctive is extremely difficult. The Hindu religion is marvellously catholic and elastic. Its theology is marked by eclecticism and tolerance and almost unlimited freedom of private worship. Its social code is much more stringent, but amongst its different castes and sections exhibits wide diversity of practice. No trait is more marked of Hindu society in general than its horror of using the meat of the cow. Yet the Chamars who profess Hinduism, but who eat beef and the flesh of dead animals, are however low in the scale included within its pale. It is easier to say who are not Hindus, and practically the separation of Hindus from non-Hindus is not a matter of so much difficulty. The people know the differences well and can easily tell who are Hindus and who are not. 5. The Act, is, therefore, applicable to: (1) All Hindus including a Virashaiva, a Lingayat, a Brahmo, Prarthana Samajist and an Arya Samajist, (2) Buddhists; (3) Jains; (4) Sikhs. 6. In this appeal the parties are admittedly tribals, the appellant being an Oraon and the respondent a Santhal. In the absence of a notification or order under Article 342 of the Constitution they are deemed to be Hindus. Even if a notification is issued under the Constitution, the Act can be applied to Scheduled Tribes as well by a further notification in terms of sub-section (2) of Section 2 of the Act. It is not disputed before us that in the Constitution (Scheduled Tribes) Order, 1950 as amended by Scheduled Castes and Scheduled Tribes Order (Amendment) Acts 63 of 1956, 108 of 1976, 18 of 1987 and 15 of 1990, both the tribes to which the parties belong are specified in Part XII. It is conceded even by the appellant that “the parties to the petition are two tribals, who otherwise profess Hinduism, but their marriage being out of the purview of the Hindu Marriage Act, 1955 in light of Section 2(2) of the Act, are thus governed only by their Santhal customs and usage”. ',\n",
       " '',\n",
       " '2   7. The appellant has, however, relied upon an alleged custom in the tribe which mandates monogamy as a rule. It is submitted that as the respondent has solemnised a second marriage during the subsistence of the first marriage with the appellant, the second marriage being void, the respondent is liable to be prosecuted for the offence punishable under Section 494 of the Indian Penal Code. 8. No custom can create an offence as it essentially deals with the civil rights of the parties and no person can be convicted of any offence except for violation of law in force at the time of commission of the act charged. Custom may be proved for the determination of the civil rights of the parties including their status, the establishment of which may be used for the purposes of proving the ingredients of an offence which, under Section 3(37) of the General Clauses Act, would mean an act or omission punishable by any law by way of fine or imprisonment. Article 20 of the Constitution, guaranteeing protection in respect of conviction of offence, provides that no person shall be convicted of any offence except for violation of law in force at the time of commission of the act charged as an offence. Law under Article 13 clause (3) of the Constitution means the law made by the legislature including intra vires statutory orders and orders made in exercise of powers conferred by the statutory rules. 9. The expression “custom and usage” has been defined under Section 3(a) of the Act as: 3. (a) the expression ‘custom’ and ‘usage’ signify any rule which, having been continuously and uniformly observed for a long time, has obtained the force of law among Hindus in any local area, tribe, community, group or family: Provided that the rule is certain and not unreasonable or opposed to public policy; and Provided further that in the case of a rule applicable only to a family it has not been discontinued by the family; 10. For custom to have the colour of a rule or law, it is necessary for the party claiming it, to plead and thereafter prove that such custom is ancient, certain and reasonable. Custom being in derogation of the general rule is required to be construed strictly. The party relying upon a custom is obliged to establish it by clear and unambiguous evidence. In Ramalakshmi Ammal v. Sivanantha Perumal Sethurayar [(1871-72) 14 Moo IA 570, 585-86] it was held: It is of the essence of special usages, modifying the ordinary law of succession that they should be ancient and invariable; and it is further essential that they should be established to be so by clear and unambiguous evidence. It is only by means of such evidence that the courts can be assured of their existence, and that they possess the conditions of antiquity and certainty on which alone their legal title to recognition depends. 12. The importance of the custom in relation to the applicability of the Act has been acknowledged by the legislature by incorporating Section 29 saving the validity of a marriage solemnised prior to the commencement of the Act which may otherwise be invalid after passing of the Act. Nothing in the Act can affect any right, recognised by custom or conferred by any said enactment to obtain the dissolution of a Hindu marriage whether solemnised before or after the commencement of the Act even without the proof of the conditions precedent for declaring the marriage invalid as incorporated in Sections 10 to 13 of the Act. 13. In this case the appellant filed a complaint in the Court of Chief Metropolitan Magistrate, New Delhi stating therein that her marriage was solemnised with the respondent in ']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Display the content of the texts\n",
    "texts[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning Steps:\n",
    "* Convert Text to Lowercase\n",
    "* Remove Punctuation and Special Characters\n",
    "* Tokenize Text into Words\n",
    "* Remove Stopwords\n",
    "* Lemmatize Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T4IY0ntkIAqJ",
    "outputId": "1a1fa0a8-fd81-4e3d-d884-661058b9d6d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Make sure to download the required NLTK data files\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # Tokenize text\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Apply lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    # Join words back to a single string\n",
    "    processed_text = ' '.join(words)\n",
    "\n",
    "    return processed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GI9JCWzTIEb5"
   },
   "outputs": [],
   "source": [
    "preprocess_text=[preprocess_text(doc) for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EkZrGd3BIIcR",
    "outputId": "67147c28-b6bc-42df-a77e-8f057ab44a55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['llb term lb family law case selected edited usha tandon kiran gupta vandana manju relan pb pankaja pinki sharma neha aneja faculty law university delhi delhi january private use course instruction',\n",
       " 'semester first course name family lawi course code lb core course credit class classesweek tutorial course objective create awareness educate student right duty member family towards special reference spousal relationship give overview student enhance understanding current law marriage divorce maintenance adoption guardianship give practical exposure student field visit family court mediation conciliation centre etc course learning outcome student able practice law court specialized matrimonial lawyer student able join research house especially issue relating woman child domestic international level unit marriage hindu law concept marriage general nature hindu marriage applicability legislation section hma condition validity marriage section hma solemnisation marriage special reference live relationship section hma rw section indian evidence act registration marriage section hma void marriage section rw hma rw section ipc voidable marriage section case dr surajmani stella kujur v durga charan hansdah air sc nagalingam v sivagami scc bhaurao shankar lokhande v state maharashtra air sc lily thomas v union india air sc pinninti venkataramana v state air ap asha qureshi v afaq qureshi air mp court motion lajja v state dlt p v k air bom babui panmato kuer v ram agya singh air pat seema v ashwani kumar scc',\n",
       " 'unit ii matrimonial remedy hindu law restitution conjugal right section hma judicial separation section ia hma divorce section b hma theory divorce b ground divorce particular emphasis cruelty desertion option puberty mutual consent irretrievable breakdown marriage seventyfirst report law commission india marriage law amendment bill case kailashwati v ayudhia parkash clj p h swaraj garg v km garg air del saroj rani v sudarshan kumar air sc ng dastane v dastane air sc sanjeev gupta v ritu gupta scc online decided may samar ghosh v jaya ghosh scj bipinchandra jaisinghbai shah v prabhavati air sc dharmendra kumar v usha kumar air sc srinivasan v varalakshmi dmc mad hirachand srinivas managaonkar v sunanda air sc sureshta devi v om prakash dmc sc amardeep singh v harveen kaur sc decided sep unit iii maintenance hindu law hindu marriage act section hindu adoption maintenance act section criminal procedure code section protection woman domestic violence act case amar kanta sen v sovana sen air cal dvelusamy v dpatchaiammal scc badshah v sou urmila badshah godse anrscc padmja sharma v ratan lal sharma air sc unit iv adoption read cara guideline hindu adoption maintenance act case brijendra v state mp air sc',\n",
       " 'adoption payal sharinee vinay pathak wife sonika sahay pathak bom cr shabnam hashmi v union india uoi or scale manju sharma vvipin scc online del decided july unit v minority guardianship hindu law hindu minority guardianship act case githa hariharan v reserve bank india scc unit vi source school muslim law unit vii marriage muslim law nikah solemnisation marriage condition validity classification type dower case m ghulam kubra bibi v mohd shafi mohd din air pesh chand patel v bismillah begum dmc sc saiyid rashid ahmad v mt anisa khatun air pc unit viii divorce muslim law extrajudicial talaq khula mubarat b judicial dissolution muslim marriage act case shamim ara v state cr lj sc masroor ahmed v delhi nct drj del ghulam sakina v falak sher allah baksh air lah yousuf rawther v sowramma air ker itwari v asghari air shayara bano v uoi sc decided august unit ix maintenance muslim law case danial latifi v union india scc',\n",
       " 'noor saba khatoon v mohd quasim air sc suggested reading prescribed legislation hindu marriage act hindu adoption maintenance act hindu minority guardianship act dissolution muslim marriage act muslim woman protection right divorce act prohibition child marriage act protection woman domestic violence act prescribed book ranganath misra rev maynes treatise hindu law usage satyajeet desai mulla principle hindu law para diwan law marriage divorce hidayatulla arshad hidayatulla mulla priciples mohomedan law tahir mahmood fyzees outline muhammedan law teaching plan week marriage hindu law week marriage hindu law week marriage hindu law week marriage hindu law week restitution conjugal right judicial separation hindu law week divorce hindu law week divorce hindu law week maintenance hindu law week maintenance adoption hindu law week adoption minority guardianship hindu law week source school muslim law marriage muslim law week marriage muslim law classification marriage week divorce muslim law week divorce muslim law',\n",
       " 'facilitating achievement course learning outcome unit course learning outcome teaching learning activity assessment task marriage hindu law case discussion lecture method moot court methodology given matrimonial remedy hindu law case discussion lecture method moot court methodology given maintenance hindu law case discussion lecture method moot court methodology given adoption hindu law case discussion lecture method given minority guardianship hindu law case discussion lecture method given source school muslim law lecture method given marriage muslim la case discussion lecture method moot court methodology given divorce muslim law case discussion lecture method given maintenance muslim law case discussion lecture method given important note topic case suggested reading given exhaustive committee teacher teaching course shall liberty revise topicscasesuggested reading student required studyrefer legislation amended time time consult latest edition book',\n",
       " 'rubric theory exam paper theory paper except cle subject llb semester exam carry mark university delhi conduct end semester descriptive exam hour duration typical theory question paper contains question printed english hindi language student required answer question question carry equal mark mark hence maximum mark paper student secure minimum mark pas paper answer may written either english hindi medium used throughout paper',\n",
       " 'surajmani stella kujur v durga charan hansdah air sc scc rp sethi j hindu purpose applicability hindu marriage act act question law determined appeal section act specifies person act applicable clause b c subsection section make act applicable person hindu religion form development including virashaiva lingayat follower brahmo prarthana arya samaj person buddhist jain sikh religion also applicable person domiciled territory india muslim christian parsi jew religion applicability act therefore comprehensive applicable person domiciled territory india muslim christian parsi jew religion term hindu defined either act indian succession act enactment legislature far back privy council bhagwan koer v jc bose ilr cal observed shall attempt lay general definition meant term hindu make accurate time sufficiently comprehensive well distinctive extremely difficult hindu religion marvellously catholic elastic theology marked eclecticism tolerance almost unlimited freedom private worship social code much stringent amongst different caste section exhibit wide diversity practice trait marked hindu society general horror using meat cow yet chamars profess hinduism eat beef flesh dead animal however low scale included within pale easier say hindu practically separation hindu nonhindus matter much difficulty people know difference well easily tell hindu act therefore applicable hindu including virashaiva lingayat brahmo prarthana samajist arya samajist buddhist jains sikh appeal party admittedly tribals appellant oraon respondent santhal absence notification order article constitution deemed hindu even notification issued constitution act applied scheduled tribe well notification term subsection section act disputed u constitution scheduled tribe order amended scheduled caste scheduled tribe order amendment act tribe party belong specified part xii conceded even appellant party petition two tribals otherwise profess hinduism marriage purview hindu marriage act light section act thus governed santhal custom usage',\n",
       " '',\n",
       " 'appellant however relied upon alleged custom tribe mandate monogamy rule submitted respondent solemnised second marriage subsistence first marriage appellant second marriage void respondent liable prosecuted offence punishable section indian penal code custom create offence essentially deal civil right party person convicted offence except violation law force time commission act charged custom may proved determination civil right party including status establishment may used purpose proving ingredient offence section general clause act would mean act omission punishable law way fine imprisonment article constitution guaranteeing protection respect conviction offence provides person shall convicted offence except violation law force time commission act charged offence law article clause constitution mean law made legislature including intra vires statutory order order made exercise power conferred statutory rule expression custom usage defined section act expression custom usage signify rule continuously uniformly observed long time obtained force law among hindu local area tribe community group family provided rule certain unreasonable opposed public policy provided case rule applicable family discontinued family custom colour rule law necessary party claiming plead thereafter prove custom ancient certain reasonable custom derogation general rule required construed strictly party relying upon custom obliged establish clear unambiguous evidence ramalakshmi ammal v sivanantha perumal sethurayar moo ia held essence special usage modifying ordinary law succession ancient invariable essential established clear unambiguous evidence mean evidence court assured existence posse condition antiquity certainty alone legal title recognition depends importance custom relation applicability act acknowledged legislature incorporating section saving validity marriage solemnised prior commencement act may otherwise invalid passing act nothing act affect right recognised custom conferred said enactment obtain dissolution hindu marriage whether solemnised commencement act even without proof condition precedent declaring marriage invalid incorporated section act case appellant filed complaint court chief metropolitan magistrate new delhi stating therein marriage solemnised respondent']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_text[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create reference document chunks\n",
    "Typically for RAG, large texts are broken down into smaller chunks at ingest time. Given a user query, only the most relevant chunks are retrieved, to pass on as context to the LLM. So as a next step, we will chunk up our reference texts before embedding and ingesting them into.\n",
    "\n",
    "\n",
    "We use the from_tiktoken_encoder method of the RecursiveCharacterTextSplitter class in LangChain. This way, the texts are split by character and recursively merged into tokens by the tokenizer as long as the chunk size (in terms of number of tokens) is less than the specified chunk size (chunk_size). Some overlap between chunks has been shown to improve retrieval, so we set an overlap of 30 characters in the chunk_overlap parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "GAoHI-jPHtmN"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Split text by tokens using the tiktoken tokenizer\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\", keep_separator=False, chunk_size=400,   chunk_overlap=30\n",
    ")\n",
    "\n",
    "def split_texts(texts):\n",
    "    chunked_texts = []\n",
    "    for text in texts:\n",
    "        chunks = text_splitter.create_documents([text])\n",
    "        chunked_texts.extend([chunk.page_content for chunk in chunks])\n",
    "    return chunked_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "fa1_4zAJISwR"
   },
   "outputs": [],
   "source": [
    "# Split the context field into chunks\n",
    "docs_texts = split_texts(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06GhuRI1IVue",
    "outputId": "4bb31d0c-8167-4326-9321-b75397664fe9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['llb term lb family law case selected edited usha tandon kiran gupta vandana manju relan pb pankaja pinki sharma neha aneja faculty law university delhi delhi january private use course instruction',\n",
       " 'semester first course name family lawi course code lb core course credit class classesweek tutorial course objective create awareness educate student right duty member family towards special reference spousal relationship give overview student enhance understanding current law marriage divorce maintenance adoption guardianship give practical exposure student field visit family court mediation conciliation centre etc course learning outcome student able practice law court specialized matrimonial lawyer student able join research house especially issue relating woman child domestic international level unit marriage hindu law concept marriage general nature hindu marriage applicability legislation section hma condition validity marriage section hma solemnisation marriage special reference live relationship section hma rw section indian evidence act registration marriage section hma void marriage section rw hma rw section ipc voidable marriage section case dr surajmani stella kujur v durga charan hansdah air sc nagalingam v sivagami scc bhaurao shankar lokhande v state maharashtra air sc lily thomas v union india air sc pinninti venkataramana v state air ap asha',\n",
       " 'v union india air sc pinninti venkataramana v state air ap asha qureshi v afaq qureshi air mp court motion lajja v state dlt p v k air bom babui panmato kuer v ram agya singh air pat seema v ashwani kumar scc',\n",
       " 'unit ii matrimonial remedy hindu law restitution conjugal right section hma judicial separation section ia hma divorce section b hma theory divorce b ground divorce particular emphasis cruelty desertion option puberty mutual consent irretrievable breakdown marriage seventyfirst report law commission india marriage law amendment bill case kailashwati v ayudhia parkash clj p h swaraj garg v km garg air del saroj rani v sudarshan kumar air sc ng dastane v dastane air sc sanjeev gupta v ritu gupta scc online decided may samar ghosh v jaya ghosh scj bipinchandra jaisinghbai shah v prabhavati air sc dharmendra kumar v usha kumar air sc srinivasan v varalakshmi dmc mad hirachand srinivas managaonkar v sunanda air sc sureshta devi v om prakash dmc sc amardeep singh v harveen kaur sc decided sep unit iii maintenance hindu law hindu marriage act section hindu adoption maintenance act',\n",
       " 'unit iii maintenance hindu law hindu marriage act section hindu adoption maintenance act section criminal procedure code section protection woman domestic violence act case amar kanta sen v sovana sen air cal dvelusamy v dpatchaiammal scc badshah v sou urmila badshah godse anrscc padmja sharma v ratan lal sharma air sc unit iv adoption read cara guideline hindu adoption maintenance act case brijendra v state mp air sc']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_texts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For embedding models, I use SBERT for embeddings\n",
    "\n",
    "BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations (~65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering.\n",
    "\n",
    "Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ohMdkMOtJCNO",
    "outputId": "c37c5ab0-7817-420f-a20d-05e8c4dbda72"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embd = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-MiniLM-L3-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ZXOAK7fwLRJ5"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define every RAPTOR phase.\n",
    "\n",
    "1. **Global Clustering with UMAP**: Reduces the dimensionality of the input embeddings globally using UMAP (Uniform Manifold Approximation and Projection).Returns a numpy array of the embeddings reduced to the specified dimensionality.\n",
    "2. **Local Clustering with UMAP**: Performs local dimensionality reduction on the embeddings using UMAP after global clustering. Returns a numpy array of the embeddings reduced to the specified dimensionality.\n",
    "3. **Determine Optimal Number of Clusters**: Determines the optimal number of clusters using the Bayesian Information Criterion (BIC) with a Gaussian Mixture Model. Returns an integer representing the optimal number of clusters found.\n",
    "4. **Gaussian Mixture Model Clustering**: Clusters embeddings using a Gaussian Mixture Model (GMM) based on a probability threshold. Returns a tuple containing the cluster labels and the number of clusters determined.\n",
    "5. **Perform Clustering**: Performs clustering by first reducing dimensionality globally, clustering with GMM, and then performing local clustering within each global cluster. Returns a list of numpy arrays, where each array contains the cluster IDs for each embedding.\n",
    "6. **Generate Embeddings for Texts**: Generates embeddings for a list of text documents. Returns a numpy array of embeddings for the given text documents.\n",
    "7. **Embed and Cluster Texts**: Embeds a list of texts and clusters them, returning a DataFrame with texts, their embeddings, and cluster labels. Returns a DataFrame containing the original texts, their embeddings, and the assigned cluster labels.\n",
    "8. **Format Texts for Summarization**: Formats the text documents in a DataFrame into a single string. Returns a single string where all text documents are joined by a specific delimiter.\n",
    "9. **Embed, Cluster, and Summarize Texts**: Embeds, clusters, and summarizes a list of texts, returning two DataFrames: one with clusters and one with summaries. Returns a tuple containing two DataFrames: one with clusters and one with summaries.\n",
    "10. **Recursive Embed, Cluster, and Summarize Texts**: Recursively embeds, clusters, and summarizes texts up to a specified level or until the number of unique clusters becomes 1. Returns a dictionary where keys are the recursion levels and values are tuples containing the clusters DataFrame and summaries DataFrame at that level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "faCH6Z5KJvgQ"
   },
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "RANDOM_SEED = 224  # Fixed seed for reproducibility\n",
    "\n",
    "### --- Code from citations referenced above (added comments and docstrings) --- ###\n",
    "\n",
    "\n",
    "def global_cluster_embeddings(\n",
    "    embeddings: np.ndarray,\n",
    "    dim: int,\n",
    "    n_neighbors: Optional[int] = None,\n",
    "    metric: str = \"cosine\",\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Perform global dimensionality reduction on the embeddings using UMAP.\n",
    "\n",
    "    Parameters:\n",
    "    - embeddings: The input embeddings as a numpy array.\n",
    "    - dim: The target dimensionality for the reduced space.\n",
    "    - n_neighbors: Optional; the number of neighbors to consider for each point.\n",
    "                   If not provided, it defaults to the square root of the number of embeddings.\n",
    "    - metric: The distance metric to use for UMAP.\n",
    "\n",
    "    Returns:\n",
    "    - A numpy array of the embeddings reduced to the specified dimensionality.\n",
    "    \"\"\"\n",
    "    if n_neighbors is None:\n",
    "        n_neighbors = int((len(embeddings) - 1) ** 0.5)\n",
    "    return umap.UMAP(\n",
    "        n_neighbors=n_neighbors, n_components=dim, metric=metric\n",
    "    ).fit_transform(embeddings)\n",
    "\n",
    "\n",
    "def local_cluster_embeddings(\n",
    "    embeddings: np.ndarray, dim: int, num_neighbors: int = 10, metric: str = \"cosine\"\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Perform local dimensionality reduction on the embeddings using UMAP, typically after global clustering.\n",
    "\n",
    "    Parameters:\n",
    "    - embeddings: The input embeddings as a numpy array.\n",
    "    - dim: The target dimensionality for the reduced space.\n",
    "    - num_neighbors: The number of neighbors to consider for each point.\n",
    "    - metric: The distance metric to use for UMAP.\n",
    "\n",
    "    Returns:\n",
    "    - A numpy array of the embeddings reduced to the specified dimensionality.\n",
    "    \"\"\"\n",
    "    return umap.UMAP(\n",
    "        n_neighbors=num_neighbors, n_components=dim, metric=metric\n",
    "    ).fit_transform(embeddings)\n",
    "\n",
    "\n",
    "def get_optimal_clusters(\n",
    "    embeddings: np.ndarray, max_clusters: int = 50, random_state: int = RANDOM_SEED\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Determine the optimal number of clusters using the Bayesian Information Criterion (BIC) with a Gaussian Mixture Model.\n",
    "\n",
    "    Parameters:\n",
    "    - embeddings: The input embeddings as a numpy array.\n",
    "    - max_clusters: The maximum number of clusters to consider.\n",
    "    - random_state: Seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - An integer representing the optimal number of clusters found.\n",
    "    \"\"\"\n",
    "    max_clusters = min(max_clusters, len(embeddings))\n",
    "    n_clusters = np.arange(1, max_clusters)\n",
    "    bics = []\n",
    "    for n in n_clusters:\n",
    "        gm = GaussianMixture(n_components=n, random_state=random_state)\n",
    "        gm.fit(embeddings)\n",
    "        bics.append(gm.bic(embeddings))\n",
    "    return n_clusters[np.argmin(bics)]\n",
    "\n",
    "\n",
    "def GMM_cluster(embeddings: np.ndarray, threshold: float, random_state: int = 0):\n",
    "    \"\"\"\n",
    "    Cluster embeddings using a Gaussian Mixture Model (GMM) based on a probability threshold.\n",
    "\n",
    "    Parameters:\n",
    "    - embeddings: The input embeddings as a numpy array.\n",
    "    - threshold: The probability threshold for assigning an embedding to a cluster.\n",
    "    - random_state: Seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple containing the cluster labels and the number of clusters determined.\n",
    "    \"\"\"\n",
    "    n_clusters = get_optimal_clusters(embeddings)\n",
    "    gm = GaussianMixture(n_components=n_clusters, random_state=random_state)\n",
    "    gm.fit(embeddings)\n",
    "    probs = gm.predict_proba(embeddings)\n",
    "    labels = [np.where(prob > threshold)[0] for prob in probs]\n",
    "    return labels, n_clusters\n",
    "\n",
    "\n",
    "def perform_clustering(\n",
    "    embeddings: np.ndarray,\n",
    "    dim: int,\n",
    "    threshold: float,\n",
    ") -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Perform clustering on the embeddings by first reducing their dimensionality globally, then clustering\n",
    "    using a Gaussian Mixture Model, and finally performing local clustering within each global cluster.\n",
    "\n",
    "    Parameters:\n",
    "    - embeddings: The input embeddings as a numpy array.\n",
    "    - dim: The target dimensionality for UMAP reduction.\n",
    "    - threshold: The probability threshold for assigning an embedding to a cluster in GMM.\n",
    "\n",
    "    Returns:\n",
    "    - A list of numpy arrays, where each array contains the cluster IDs for each embedding.\n",
    "    \"\"\"\n",
    "    if len(embeddings) <= dim + 1:\n",
    "        # Avoid clustering when there's insufficient data\n",
    "        return [np.array([0]) for _ in range(len(embeddings))]\n",
    "\n",
    "    # Global dimensionality reduction\n",
    "    reduced_embeddings_global = global_cluster_embeddings(embeddings, dim)\n",
    "    # Global clustering\n",
    "    global_clusters, n_global_clusters = GMM_cluster(\n",
    "        reduced_embeddings_global, threshold\n",
    "    )\n",
    "\n",
    "    all_local_clusters = [np.array([]) for _ in range(len(embeddings))]\n",
    "    total_clusters = 0\n",
    "\n",
    "    # Iterate through each global cluster to perform local clustering\n",
    "    for i in range(n_global_clusters):\n",
    "        # Extract embeddings belonging to the current global cluster\n",
    "        global_cluster_embeddings_ = embeddings[\n",
    "            np.array([i in gc for gc in global_clusters])\n",
    "        ]\n",
    "\n",
    "        if len(global_cluster_embeddings_) == 0:\n",
    "            continue\n",
    "        if len(global_cluster_embeddings_) <= dim + 1:\n",
    "            # Handle small clusters with direct assignment\n",
    "            local_clusters = [np.array([0]) for _ in global_cluster_embeddings_]\n",
    "            n_local_clusters = 1\n",
    "        else:\n",
    "            # Local dimensionality reduction and clustering\n",
    "            reduced_embeddings_local = local_cluster_embeddings(\n",
    "                global_cluster_embeddings_, dim\n",
    "            )\n",
    "            local_clusters, n_local_clusters = GMM_cluster(\n",
    "                reduced_embeddings_local, threshold\n",
    "            )\n",
    "\n",
    "        # Assign local cluster IDs, adjusting for total clusters already processed\n",
    "        for j in range(n_local_clusters):\n",
    "            local_cluster_embeddings_ = global_cluster_embeddings_[\n",
    "                np.array([j in lc for lc in local_clusters])\n",
    "            ]\n",
    "            indices = np.where(\n",
    "                (embeddings == local_cluster_embeddings_[:, None]).all(-1)\n",
    "            )[1]\n",
    "            for idx in indices:\n",
    "                all_local_clusters[idx] = np.append(\n",
    "                    all_local_clusters[idx], j + total_clusters\n",
    "                )\n",
    "\n",
    "        total_clusters += n_local_clusters\n",
    "\n",
    "    return all_local_clusters\n",
    "\n",
    "\n",
    "### --- Our code below --- ###\n",
    "\n",
    "\n",
    "def embed(texts):\n",
    "    \"\"\"\n",
    "    Generate embeddings for a list of text documents.\n",
    "\n",
    "    This function assumes the existence of an `embd` object with a method `embed_documents`\n",
    "    that takes a list of texts and returns their embeddings.\n",
    "\n",
    "    Parameters:\n",
    "    - texts: List[str], a list of text documents to be embedded.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: An array of embeddings for the given text documents.\n",
    "    \"\"\"\n",
    "    text_embeddings = embd.embed_documents(texts)\n",
    "    text_embeddings_np = np.array(text_embeddings)\n",
    "    return text_embeddings_np\n",
    "\n",
    "\n",
    "def embed_cluster_texts(texts):\n",
    "    \"\"\"\n",
    "    Embeds a list of texts and clusters them, returning a DataFrame with texts, their embeddings, and cluster labels.\n",
    "\n",
    "    This function combines embedding generation and clustering into a single step. It assumes the existence\n",
    "    of a previously defined `perform_clustering` function that performs clustering on the embeddings.\n",
    "\n",
    "    Parameters:\n",
    "    - texts: List[str], a list of text documents to be processed.\n",
    "\n",
    "    Returns:\n",
    "    - pandas.DataFrame: A DataFrame containing the original texts, their embeddings, and the assigned cluster labels.\n",
    "    \"\"\"\n",
    "    text_embeddings_np = embed(texts)  # Generate embeddings\n",
    "    cluster_labels = perform_clustering(\n",
    "        text_embeddings_np, 10, 0.1\n",
    "    )  # Perform clustering on the embeddings\n",
    "    df = pd.DataFrame()  # Initialize a DataFrame to store the results\n",
    "    df[\"text\"] = texts  # Store original texts\n",
    "    df[\"embd\"] = list(text_embeddings_np)  # Store embeddings as a list in the DataFrame\n",
    "    df[\"cluster\"] = cluster_labels  # Store cluster labels\n",
    "    return df\n",
    "\n",
    "\n",
    "def fmt_txt(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Formats the text documents in a DataFrame into a single string.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the 'text' column with text documents to format.\n",
    "\n",
    "    Returns:\n",
    "    - A single string where all text documents are joined by a specific delimiter.\n",
    "    \"\"\"\n",
    "    unique_txt = df[\"text\"].tolist()\n",
    "    return \"--- --- \\n --- --- \".join(unique_txt)\n",
    "\n",
    "\n",
    "def embed_cluster_summarize_texts(\n",
    "    texts: List[str], level: int\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Embeds, clusters, and summarizes a list of texts. This function first generates embeddings for the texts,\n",
    "    clusters them based on similarity, expands the cluster assignments for easier processing, and then summarizes\n",
    "    the content within each cluster.\n",
    "\n",
    "    Parameters:\n",
    "    - texts: A list of text documents to be processed.\n",
    "    - level: An integer parameter that could define the depth or detail of processing.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple containing two DataFrames:\n",
    "      1. The first DataFrame (`df_clusters`) includes the original texts, their embeddings, and cluster assignments.\n",
    "      2. The second DataFrame (`df_summary`) contains summaries for each cluster, the specified level of detail,\n",
    "         and the cluster identifiers.\n",
    "    \"\"\"\n",
    "\n",
    "    # Embed and cluster the texts, resulting in a DataFrame with 'text', 'embd', and 'cluster' columns\n",
    "    df_clusters = embed_cluster_texts(texts)\n",
    "\n",
    "    # Prepare to expand the DataFrame for easier manipulation of clusters\n",
    "    expanded_list = []\n",
    "\n",
    "    # Expand DataFrame entries to document-cluster pairings for straightforward processing\n",
    "    for index, row in df_clusters.iterrows():\n",
    "        for cluster in row[\"cluster\"]:\n",
    "            expanded_list.append(\n",
    "                {\"text\": row[\"text\"], \"embd\": row[\"embd\"], \"cluster\": cluster}\n",
    "            )\n",
    "\n",
    "    # Create a new DataFrame from the expanded list\n",
    "    expanded_df = pd.DataFrame(expanded_list)\n",
    "\n",
    "    # Retrieve unique cluster identifiers for processing\n",
    "    all_clusters = expanded_df[\"cluster\"].unique()\n",
    "\n",
    "    print(f\"--Generated {len(all_clusters)} clusters--\")\n",
    "\n",
    "    # Summarization\n",
    "    template = \"\"\"Please summarize the paragraph without changing the context.\n",
    "     If the solution is not available in the text,\n",
    "     explain that you are not sure. Do not make up any information...\n",
    "\n",
    "    Documentation:\n",
    "    {context}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    chain = prompt | model | StrOutputParser()\n",
    "\n",
    "    # Format text within each cluster for summarization\n",
    "    summaries = []\n",
    "    for i in all_clusters:\n",
    "        df_cluster = expanded_df[expanded_df[\"cluster\"] == i]\n",
    "        formatted_txt = fmt_txt(df_cluster)\n",
    "        summaries.append(chain.invoke({\"context\": formatted_txt}))\n",
    "\n",
    "    # Create a DataFrame to store summaries with their corresponding cluster and level\n",
    "    df_summary = pd.DataFrame(\n",
    "        {\n",
    "            \"summaries\": summaries,\n",
    "            \"level\": [level] * len(summaries),\n",
    "            \"cluster\": list(all_clusters),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return df_clusters, df_summary\n",
    "\n",
    "\n",
    "def recursive_embed_cluster_summarize(\n",
    "    texts: List[str], level: int = 1, n_levels: int = 3\n",
    ") -> Dict[int, Tuple[pd.DataFrame, pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Recursively embeds, clusters, and summarizes texts up to a specified level or until\n",
    "    the number of unique clusters becomes 1, storing the results at each level.\n",
    "\n",
    "    Parameters:\n",
    "    - texts: List[str], texts to be processed.\n",
    "    - level: int, current recursion level (starts at 1).\n",
    "    - n_levels: int, maximum depth of recursion.\n",
    "\n",
    "    Returns:\n",
    "    - Dict[int, Tuple[pd.DataFrame, pd.DataFrame]], a dictionary where keys are the recursion\n",
    "      levels and values are tuples containing the clusters DataFrame and summaries DataFrame at that level.\n",
    "    \"\"\"\n",
    "    results = {}  # Dictionary to store results at each level\n",
    "\n",
    "    # Perform embedding, clustering, and summarization for the current level\n",
    "    df_clusters, df_summary = embed_cluster_summarize_texts(texts, level)\n",
    "\n",
    "    # Store the results of the current level\n",
    "    results[level] = (df_clusters, df_summary)\n",
    "\n",
    "    # Determine if further recursion is possible and meaningful\n",
    "    unique_clusters = df_summary[\"cluster\"].nunique()\n",
    "    if level < n_levels and unique_clusters > 1:\n",
    "        # Use summaries as the input texts for the next level of recursion\n",
    "        new_texts = df_summary[\"summaries\"].tolist()\n",
    "        next_level_results = recursive_embed_cluster_summarize(\n",
    "            new_texts, level + 1, n_levels\n",
    "        )\n",
    "\n",
    "        # Merge the results from the next level into the current results dictionary\n",
    "        results.update(next_level_results)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HuiE1F9FK9lc",
    "outputId": "7fdc8a36-ec4c-4819-ade7-cc314980dc68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Generated 316 clusters--\n",
      "--Generated 61 clusters--\n",
      "--Generated 11 clusters--\n",
      "--Generated 1 clusters--\n"
     ]
    }
   ],
   "source": [
    "leaf_texts = docs_texts\n",
    "results = recursive_embed_cluster_summarize(leaf_texts, level=1, n_levels=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate final summaries\n",
    "\n",
    "1. **Tree Traversal Retrieval:** Tree traversal starts at the root level of the tree and retrieves the top k documents of a node based on the cosine similarity of the vector embedding. So, at each level it retrieves top k documents from the child node.\n",
    "2. **Collapsed Tree Retrieval:** Collapsed Tree retrieval is a much simpler method. It collapses all the trees into a single layer and retrieves nodes until a threshold number of tokens is reached based on the cosine similarity of the query vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "m_5rltnvMM3m"
   },
   "outputs": [],
   "source": [
    "all_texts= leaf_texts.copy()\n",
    "\n",
    "# Iterate through the results to extract summaries from each level and add them to all_texts\n",
    "for level in sorted(results.keys()):\n",
    "    # Extract summaries from the current level's DataFrame\n",
    "    summaries = results[level][1][\"summaries\"].tolist()\n",
    "    # Extend all_texts with the summaries from the current level\n",
    "    all_texts.extend(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "rgCIXtd_Xouv"
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "\n",
    "# Write list to a file\n",
    "with open('summary.txt', 'w') as file:\n",
    "    file.write(str(all_texts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the texts into vectorstore\n",
    "* To store the vectors, we use the Milvus database.[Milvus](https://milvus.io/docs/)\n",
    "* Milvus is a strong vector database designed specifically for processing and querying large amounts of vector data.\n",
    "* It stands out for its exceptional performance and scalability, making it ideal for machine learning, deep learning, similarity search jobs, and recommendation systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "XHf658doMlTk"
   },
   "outputs": [],
   "source": [
    "from langchain_milvus.vectorstores import Milvus\n",
    "URI = \"/content/drive/MyDrive/rag_with_raptor/database/milvus_rag.db\"\n",
    "\n",
    "vector_db = Milvus.from_texts(\n",
    "    texts= all_texts,\n",
    "    embedding=embd,\n",
    "    connection_args={\"uri\": URI},\n",
    "    # metadatas= chunks.metadatas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8tZMIfX_MaTt",
    "outputId": "adb3df0a-70c8-485a-abb5-0c5537d23d41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paragraph appears to be a collection of notes and points related to the Indian Constitution, industrial law, and labor rights. It discusses various topics such as the fundamental rights of citizens, the concept of socioeconomic justice, the importance of labor laws, and the role of the International Labor Organization (ILO) in promoting workers' rights.\n",
      "\n",
      "The text mentions several articles and sections of the Indian Constitution, including Articles 19, 21, 23, and 24, as well as the Directive Principles of State Policy in Part IV of the Constitution. It also references various labor laws and regulations, such as the Factories Act, the Employee's State Insurance Act, and the Minimum Wage Act.\n",
      "\n",
      "The paragraph also touches on the importance of social justice, the need for fair wages, and the right to collective bargaining and strike. It quotes from several court judgments and references international labor standards, including the ILO's Declaration on Fundamental Principles and Rights at Work.\n",
      "\n",
      "However, without further context or clarification, it is difficult to provide a more specific summary of the paragraph's content. If you have any specific questions or would like me to clarify certain points, I would be happy to try and assist you.\n",
      "This paragraph appears to be a collection of legal documents, court cases, and constitutional references. It discusses various topics related to the Indian constitution, including the powers of the Parliament and the Supreme Court, the concept of judicial review, and the role of tribunals. The text mentions several court cases, such as John Vallamattom v. Union of India and Adarand Constructor Inc. v. Pena, and references various constitutional provisions, including Article 32 and Article 226.\n",
      "\n",
      "However, without further context or information, it is difficult to summarize the paragraph without changing its context. The text appears to be a collection of legal references and court cases, and it is unclear what specific aspect or topic is being discussed. If you could provide more context or information about the paragraph, I would be happy to try and summarize it for you.\n",
      "This appears to be a documentation of various court cases and laws related to administrative and judicial decisions in India. The text discusses the Industrial Dispute Act, the Administrative Act, and the Judicial Act, as well as specific cases such as CP Sarathy vs. CP Sarathy, KP Krishnan vs. State of Bombay, and Meerut University vs. Union of India.\n",
      "\n",
      "The text also mentions the Constitution Bench of the Supreme Court and the importance of natural justice in administrative action. It discusses the power of the central government to constitute new services, including the Indian Forest Service, and the need for a quorum in the Indian Forest Service Recruitment Rule.\n",
      "\n",
      "Additionally, the text touches on the topic of judicial review and the power of the court to issue writs, such as mandamus. It also discusses the concept of administrative tribunals and the importance of a fair and transparent selection process.\n",
      "\n",
      "However, without further context, it is difficult to provide a more detailed summary of the text without changing its context. If you could provide more information about what you are looking for or what you would like to know, I would be happy to try and assist you further.\n",
      "This paragraph appears to be a complex and technical discussion about the legislative powers of the British Parliament and the Indian Parliament, particularly in regards to the Indian Council Act and the Indian Constitution. It mentions the concept of delegation of power, the separation of powers, and the exercise of legislative authority within the limits laid down by the constitution. It also references various court decisions and constitutional provisions.\n",
      "\n",
      "However, I am not sure what the main point or conclusion of the paragraph is, as it seems to be a collection of legal and constitutional concepts and principles rather than a clear argument or statement.\n"
     ]
    }
   ],
   "source": [
    "# Perform a similarity search\n",
    "query = \"Explain Article 14 of the Indian Constitution?\"\n",
    "docs = vector_db.similarity_search(query)\n",
    "for doc in docs:\n",
    "  print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1ADIruSXQln",
    "outputId": "98d7819b-1ba8-4b09-a918-8577d1c69fc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet pymilvus[model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Techniques:\n",
    "\n",
    "* Milvus Hybrid Search retriever Milvus Hybrid Search retriever combines the advantages of dense and sparse vector searches.\n",
    "* BM25 Retriever (BM stands for best matching) is a ranking mechanism used by search engines to determine the relevance of pages to a particular search query.\n",
    "* Dense Passage Retrieval (DPR) - is a set of tools and models for state-of-the-art open-domain Q&A research. It is based on the following paper:DPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Milvus Hybrid Search retriever, which combines the strengths of both dense and sparse vector search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "H365-Gu6XUWR"
   },
   "outputs": [],
   "source": [
    "from pymilvus import (\n",
    "    Collection,\n",
    "    CollectionSchema,\n",
    "    DataType,\n",
    "    FieldSchema,\n",
    "    WeightedRanker,\n",
    "    connections,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "pfAMnp9uXXMr"
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_milvus.retrievers import MilvusCollectionHybridSearchRetriever\n",
    "from langchain_milvus.utils.sparse import BM25SparseEmbedding\n",
    "# from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "26F_NprvXbPQ"
   },
   "outputs": [],
   "source": [
    "CONNECTION_URI = \"/content/drive/MyDrive/rag_with_raptor/database/milvus_hybrid_search.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n8wd44jtXihA",
    "outputId": "2540792d-9c95-4b04-85a0-31604192fd9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dense_embedding_func = OpenAIEmbeddings()\n",
    "dense_dim = len(embd.embed_query(all_texts[1]))\n",
    "dense_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Note that the output of sparse embedding is a set of sparse vectors, which represents the index and weight of the keywords of the input text.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lbyuahXiXlzN",
    "outputId": "dfc3ac0b-6f74-4396-c459-87d978fa4fb7",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 6.510754,\n",
       " 3: 8.982522,\n",
       " 4: 1.5737364,\n",
       " 5: 0.06933469,\n",
       " 27: 13.536732,\n",
       " 29: 5.9989367,\n",
       " 30: 2.0308025,\n",
       " 31: 2.338879,\n",
       " 32: 7.6103578,\n",
       " 33: 2.4285266,\n",
       " 34: 5.409163,\n",
       " 35: 4.55588,\n",
       " 36: 2.6417124,\n",
       " 37: 7.6103578,\n",
       " 38: 7.0992017,\n",
       " 39: 2.0968235,\n",
       " 40: 3.1927638,\n",
       " 41: 4.352872,\n",
       " 42: 3.274152,\n",
       " 43: 18.542564,\n",
       " 44: 1.2016146,\n",
       " 45: 2.1381311,\n",
       " 46: 2.2027373,\n",
       " 47: 3.6011338,\n",
       " 48: 7.4210925,\n",
       " 49: 2.9137743,\n",
       " 50: 7.6103578,\n",
       " 51: 6.3681736,\n",
       " 52: 3.804253,\n",
       " 53: 4.55588,\n",
       " 54: 4.524294,\n",
       " 55: 3.5036724,\n",
       " 56: 4.7303886,\n",
       " 57: 15.917902,\n",
       " 58: 2.376485,\n",
       " 59: 2.4153028,\n",
       " 60: 2.6740603,\n",
       " 61: 4.3015594,\n",
       " 62: 5.494893,\n",
       " 63: 5.7618856,\n",
       " 64: 3.8767748,\n",
       " 65: 4.809526,\n",
       " 66: 0.41468054,\n",
       " 67: 5.7618856,\n",
       " 68: 3.9814482,\n",
       " 69: 4.406886,\n",
       " 70: 2.5999458,\n",
       " 71: 2.086702,\n",
       " 72: 4.55588,\n",
       " 73: 7.151829,\n",
       " 74: 3.0236313,\n",
       " 75: 4.6569633,\n",
       " 76: 3.8281357,\n",
       " 77: 4.5884743,\n",
       " 78: 2.7769804,\n",
       " 79: 5.207497,\n",
       " 80: 1.7268566,\n",
       " 81: 0.9344973,\n",
       " 82: 2.3024037,\n",
       " 83: 2.306403,\n",
       " 84: 3.9632545,\n",
       " 85: 3.1089575,\n",
       " 86: 3.4037583,\n",
       " 87: 3.4581056,\n",
       " 88: 5.0897284,\n",
       " 89: 2.589735,\n",
       " 90: 2.0179925,\n",
       " 91: 1.8008373,\n",
       " 92: 1.4851323,\n",
       " 93: 2.0469944,\n",
       " 94: 1.3922824,\n",
       " 95: 31.548765,\n",
       " 96: 1.5183612,\n",
       " 97: 2.3638191,\n",
       " 98: 4.524294,\n",
       " 99: 2.4285266,\n",
       " 100: 22.831074,\n",
       " 101: 2.459965,\n",
       " 102: 2.4508975,\n",
       " 103: 1.621935,\n",
       " 104: 3.2555292,\n",
       " 105: 3.1334298,\n",
       " 106: 4.435,\n",
       " 107: 4.206033,\n",
       " 108: 4.0978737,\n",
       " 109: 7.0992017,\n",
       " 110: 7.0992017,\n",
       " 111: 7.0992017,\n",
       " 112: 5.1810694,\n",
       " 113: 6.510754,\n",
       " 114: 6.309753,\n",
       " 115: 7.0992017,\n",
       " 116: 8.566539,\n",
       " 117: 7.312274,\n",
       " 118: 6.510754,\n",
       " 119: 7.0992017,\n",
       " 120: 2.8011749,\n",
       " 121: 6.762399,\n",
       " 122: 5.6614714,\n",
       " 123: 6.762399,\n",
       " 124: 1.134417,\n",
       " 125: 4.9891043,\n",
       " 126: 6.510754,\n",
       " 127: 5.409163,\n",
       " 128: 2.07666,\n",
       " 129: 1.3008238,\n",
       " 130: 6.762399,\n",
       " 131: 6.762399,\n",
       " 132: 4.9891043,\n",
       " 133: 6.309753}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_embedding_func = BM25SparseEmbedding(corpus=all_texts)\n",
    "sparse_embedding_func.embed_query(all_texts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Milvus Collection and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "M7VpEAWWYCZk"
   },
   "outputs": [],
   "source": [
    "connections.connect(uri=CONNECTION_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define field names and their data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "ddZu5vs4YF-5"
   },
   "outputs": [],
   "source": [
    "pk_field = \"doc_id\"\n",
    "dense_field = \"dense_vector\"\n",
    "sparse_field = \"sparse_vector\"\n",
    "text_field = \"text\"\n",
    "fields = [\n",
    "    FieldSchema(\n",
    "        name=pk_field,\n",
    "        dtype=DataType.VARCHAR,\n",
    "        is_primary=True,\n",
    "        auto_id=True,\n",
    "        max_length=100,\n",
    "    ),\n",
    "    FieldSchema(name=dense_field, dtype=DataType.FLOAT_VECTOR, dim=dense_dim),\n",
    "    FieldSchema(name=sparse_field, dtype=DataType.SPARSE_FLOAT_VECTOR),\n",
    "    FieldSchema(name=text_field, dtype=DataType.VARCHAR, max_length=65_535),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a collection with the defined schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "oV4cnPIbYJDO"
   },
   "outputs": [],
   "source": [
    "schema = CollectionSchema(fields=fields, enable_dynamic_field=False)\n",
    "collection = Collection(\n",
    "    name=\"BriefSummaryofLaws\", schema=schema, consistency_level=\"Strong\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define index for dense and sparse vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "dz_2eR0nYP1s"
   },
   "outputs": [],
   "source": [
    "dense_index = {\"index_type\": \"FLAT\", \"metric_type\": \"IP\"}\n",
    "collection.create_index(\"dense_vector\", dense_index)\n",
    "sparse_index = {\"index_type\": \"SPARSE_INVERTED_INDEX\", \"metric_type\": \"IP\"}\n",
    "collection.create_index(\"sparse_vector\", sparse_index)\n",
    "collection.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert entities into the collection and load the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "pph2QVQLYTLN"
   },
   "outputs": [],
   "source": [
    "entities = []\n",
    "for text in all_texts:\n",
    "    entity = {\n",
    "        dense_field: embd.embed_documents([text])[0],\n",
    "        sparse_field: sparse_embedding_func.embed_documents([text])[0],\n",
    "        text_field: text,\n",
    "    }\n",
    "    entities.append(entity)\n",
    "collection.insert(entities)\n",
    "collection.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build RAG chain with Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Retriever\n",
    "#### Define search parameters for sparse and dense fields, and create a retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "jTzdPMzNYcYl"
   },
   "outputs": [],
   "source": [
    "sparse_search_params = {\"metric_type\": \"IP\"}\n",
    "dense_search_params = {\"metric_type\": \"IP\", \"params\": {}}\n",
    "retriever = MilvusCollectionHybridSearchRetriever(\n",
    "    collection=collection,\n",
    "    rerank=WeightedRanker(0.5, 0.5),\n",
    "    anns_fields=[dense_field, sparse_field],\n",
    "    field_embeddings=[embd, sparse_embedding_func],\n",
    "    field_search_params=[dense_search_params, sparse_search_params],\n",
    "    top_k=3,\n",
    "    text_field=text_field,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the input parameters of this Retriever, we use a dense embedding and a sparse embedding to perform hybrid search on the two fields of this Collection, and use WeightedRanker for reranking. Finally, 3 top-K Documents will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Bv9INV-YrHY",
    "outputId": "29915c93-4ba7-4d17-8b22-40912446141f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'doc_id': '451298459402371835'}, page_content='lesson n constitution labour law'),\n",
       " Document(metadata={'doc_id': '451298459402372918'}, page_content='lesson n industrial labour law audit'),\n",
       " Document(metadata={'doc_id': '451298459402371881'}, page_content='lesson n international labour organisation'),\n",
       " Document(metadata={'doc_id': '451298459402373793'}, page_content=\"The text appears to be a study material for a professional programme on labour law, focusing on the importance of labour audits and compliance with labour legislation. It explains that a labour audit is a process to ensure sound corporate governance and detect non-compliance with various labour laws applicable to an organization. The text highlights the benefits of labour audits, including boosting morale among workers, increasing productivity, and promoting good corporate governance. It also mentions the importance of compulsory labour audits to ensure compliance with past defaults and reduce the risk of penalties and fines. The text concludes by emphasizing the need for labour audits to improve the country's image internationally and reduce non-compliance with labour legislation.\"),\n",
       " Document(metadata={'doc_id': '451298459402372073'}, page_content='contract labour process operation work establishment selftest question explain provision applicability act abolish contract labour act write rule wrt canteen contract labour regulation abolition central rule responsible payment wage act contractor fails make payment wage contract labour briefly discus case steel authority india v national union water front worker others explain provision registration establishment act'),\n",
       " Document(metadata={'doc_id': '451298459402372917'}, page_content='labour audit boost morale worker large extent increase social security labour audit increased productivity view lower absenteeism enterprise higher productivity higher profit compulsory labour audit ensure compliance past default self test question briefly explain scope labour audit briefly explain benefit labour audit discus certificate covered contract labour regulation abolition act verified labour audit discus certificate covered factory act verified labour audit discus certificate covered industrial dispute act verified labour audit')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"Explain Labour Law?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing reranking with CohereRerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's wrap our base retriever with a `ContextualCompressionRetriever`. We'll add an `CohereRerank`, uses the Cohere rerank endpoint to rerank the returned results. Do note that it is mandatory to specify the model name in CohereRerank!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "FLO86cA8ZS2j"
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain_cohere import CohereRerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "nq_XQZIzZes-"
   },
   "outputs": [],
   "source": [
    "os.environ['COHERE_API_KEY'] = 'Your_COHERE_API_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "p1d8Z9YAZhbP"
   },
   "outputs": [],
   "source": [
    "compressor = CohereRerank(model=\"rerank-english-v3.0\")\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "uOlTlLRtZlW0"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=model, retriever=compression_retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xDibl9iAZr0y",
    "outputId": "cdbc8cb8-bb95-4f59-b5c3-4054a8068423"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Explain Matrimonial Remedies under Hindu Law?',\n",
       " 'result': 'Based on the provided context, here is an explanation of Matrimonial Remedies under Hindu Law:\\n\\nUnder Hindu Law, a wife may choose to live separately from her husband due to various reasons, including employment, financial difficulties, or personal reasons. In such cases, the wife may seek various matrimonial remedies to resolve the issue.\\n\\nSome of the matrimonial remedies available to a wife under Hindu Law include:\\n\\n1. Judicial Separation: This is a remedy where the court grants a decree of separation, allowing the wife to live separately from her husband without dissolving the marriage.\\n2. Divorce: This is a remedy where the court dissolves the marriage, allowing the wife to remarry.\\n3. Maintenance: This is a remedy where the court grants the wife a regular payment of money to maintain her livelihood, especially in cases where the husband has failed to provide for her.\\n\\nIn order to avail these remedies, the wife may need to establish grounds for separation or divorce, such as:\\n\\n* Desertion: Where the husband has abandoned the wife without a reasonable cause.\\n* Adultery: Where the husband has committed adultery.\\n* Cruelty: Where the husband has treated the wife with cruelty.\\n* Renunciation: Where the wife has renounced the husband.\\n\\nThese remedies are governed by the Hindu Marriage Act, 1955, and the Matrimonial Causes Act, 1973.\\n\\nIt is important to note that Hindu Law is a complex and nuanced area of law, and the availability and application of these remedies may vary depending on the specific circumstances of each case.'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Explain Matrimonial Remedies under Hindu Law?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nVhrtjjbZ3Lj",
    "outputId": "e321cf39-2c0f-4a1f-a15e-adbf3da766dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Explain Article 14 of the Indian Constitution.?',\n",
       " 'result': 'Article 14 of the Indian Constitution is the \"Equality before the Law\" clause. It states:\\n\\n\"Equality before the law is a constitutional principle that no person shall be denied the equal protection of the laws nor shall there be any discrimination by the State on the ground of religion, race, caste, sex, place of birth or any of them.\"\\n\\nIn simpler terms, Article 14 ensures that every individual is treated equally by the law and that there is no discrimination on the basis of certain grounds specified in the Constitution. This means that the State cannot discriminate against any person or group of people in the exercise of its powers or functions, such as in the allocation of resources, provision of services, or enforcement of laws.\\n\\nArticle 14 has been interpreted by the Supreme Court of India to mean that all persons, regardless of their background or characteristics, have an equal claim to the protection of the law and that the State cannot deny anyone equal protection of the law. It has also been held that Article 14 not only prohibits discrimination but also requires the State to ensure equal access to opportunities, facilities, and benefits.\\n\\nIn the context of the document you provided, Article 14 is referred to in relation to the cinema tax case, where it is argued that the taxation rate may be arbitrary and violative of Article 14, which guarantees equality before the law.'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Explain Article 14 of the Indian Constitution.?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dE6ppza0a5Op",
    "outputId": "e036988c-3f61-4245-d48a-8f5655de7492"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Explain law of wages',\n",
       " 'result': 'Based on the provided text, I will explain the concept of \"minimum rate wage\" and \"payment of wages\" under Indian labor laws.\\n\\nIn India, the concept of minimum rate wage is defined under the Minimum Wages Act, 1948. The Act provides for the fixing of minimum rates of wages in certain employments and the payment of wages to employees at such rates. The minimum rate wage is the lowest rate that an employer is required to pay to an employee for their work.\\n\\nAccording to the Act, the minimum rate wage is fixed by the state governments, taking into account the standard of living, cost of living, and other factors relevant to the workers in that state. The minimum rate wage is applicable to all employees employed in scheduled employment, which includes industries such as manufacturing, mining, and construction.\\n\\nThe payment of wages to employees is governed by the Payment of Wages Act, 1936. This Act provides for the payment of wages to employees on a regular basis, usually on a monthly or bi-monthly basis. The Act also provides for the payment of wages during holidays, sick leave, and maternity leave.\\n\\nUnder this Act, employers are required to pay wages to their employees within a specified time limit, usually within 7-10 days of the end of the wage period. The Act also provides for penalties and fines for employers who fail to pay wages to their employees within the specified time limit.\\n\\nIn addition to the Minimum Wages Act and the Payment of Wages Act, there are other laws and regulations that govern the payment of wages to employees in India, such as the Contract Labour (Regulation and Abolition) Act, 1970. This Act provides for the regulation and abolition of contract labor and the payment of wages to contract workers.\\n\\nIn summary, the law of wages in India is governed by the Minimum Wages Act, 1948, the Payment of Wages Act, 1936, and other related laws and regulations. These laws provide for the fixing of minimum rates of wages, the payment of wages to employees on a regular basis, and the penalties and fines for employers who fail to comply with these laws.'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Explain law of wages\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
